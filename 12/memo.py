# -*- coding: utf-8 -*-
cross validation
1.
test를 더 좋게 할 수 있는 방법=>전처리, 제약...

50번째 줄 훈련하고 평가를 test 데이터로 하는게 문제임.
고1,고2,고3 공부하고 마지막에 최종적으로 수능시험을 봐야하는데 지금 상황은
중간고사는 0점인데 수능은 100점 맞은 상황과 같은거임.

62번째 줄 최고의 성적 출력


2.
검증 데이터.

이번에도 52번째 줄 사람이기 때문에 문제임.
valid의 random_state를 1->10000으로 바꾸면 엉망일 수 있음(좋은 데이터에 껴맞추려하면 안됨)
교차검증을 통해서 결과를 내야함.


3.
KFold cross_val_score를 통해서 교차검증.

76번째 줄에 **를 찍어서 파라미터 세팅할 수 있음(2번째 py코드랑 비교해보면 알수 있음)

for문이 너무 많아지면 가독성 별로임->4번째 py파일


4.
32번째 줄 param_grid 리스트로 만듦
GridSearchCv로 간단하게 코딩 완료.


5.
57~65 줄 잠깐 주석처리=> 하이퍼 파라메터 연결이 안됨
위에꺼 살리고, 45~47 줄 주석처리=> 잘됨
이유는 아래와 같음(scikit-learn 홈페이지에 있음)
Warning The choice of the algorithm depends on the penalty chosen: Supported penalties by solver:
‘newton-cg’ - [‘l2’, ‘none’]
‘lbfgs’ - [‘l2’, ‘none’]
‘liblinear’ - [‘l1’, ‘l2’]
‘sag’ - [‘l2’, ‘none’]
‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, ‘none’]
**57~65 조건부 매게변수 다루는거 매 중요**



pipeline
1.
classification_report로 디테일한 성적 확인


2.
전처리 추가(StandardScaler)

///이해 안돼서 강의 다시 찾아보기 실시간으로 4:40분 쯤이였음
스케일링 처리할 때 이상치 처리. 
y 데이터에서 0과 1에 대한 차이를 구할 수 있음.
연속된 수치를 찾을 때에도 구간별로 차이가 있을 수 있는거 고려.


3.
class_weight 0과 1 비율을 맞춰줌(0이 99개고 1이 1개면 의미가 없으니깐 적은 정답데이터여도
                          패널티를 줘서 맞출 수 있게끔 함)


4.(매우중요**)파이프라인
여기서 말하는 파이프라인은 자료구조의 큐를 생각하면 됨
파이프라인은 작업의 순서를 지정해주는 녀석이다.
마지막꺼를 제외한 대부분은 전부 머신러닝으로 들어감


5.











































